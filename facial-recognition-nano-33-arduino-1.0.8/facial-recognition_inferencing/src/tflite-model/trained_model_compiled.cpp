/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 28.02.2023 22:49:47

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

constexpr int kTensorArenaSize = 12192;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_CONV_2D, OP_MAX_POOL_2D, OP_RESHAPE, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

TfLiteContext ctx{};
TfLiteTensor tflTensors[15];
TfLiteEvalTensor tflEvalTensors[15];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[7];

const TfArray<4, int> tensor_dimension0 = { 4, { 1,32,32,3 } };
const TfArray<1, float> quant0_scale = { 1, { 0.0039215688593685627, } };
const TfArray<1, int> quant0_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(8) int32_t tensor_data1[2] = { -1, 1024, };
const TfArray<1, int> tensor_dimension1 = { 1, { 2 } };
const ALIGN(16) int8_t tensor_data2[8*3*3*3] = { 
  /* [0][0][][] */ -72,49,-74, 82,96,-54, 60,86,90, 
  /* [0][1][][] */ -50,-4,89, 13,122,-19, -81,-20,5, 
  /* [0][2][][] */ -29,-35,-78, 67,4,54, 127,124,-98, 
  /* [1][0][][] */ 25,-6,-61, -67,33,-1, 19,-124,-24, 
  /* [1][1][][] */ 98,32,-113, 127,55,-29, 94,-4,25, 
  /* [1][2][][] */ 57,-17,-101, 79,-66,-103, 112,80,12, 
  /* [2][0][][] */ 21,-81,-63, 127,-117,-91, -105,115,-31, 
  /* [2][1][][] */ -56,4,124, 77,39,-38, -120,40,-1, 
  /* [2][2][][] */ -24,82,-72, 21,-30,73, -47,-42,12, 
  /* [3][0][][] */ -116,111,-29, 126,127,-92, -4,90,-25, 
  /* [3][1][][] */ 45,38,17, 28,119,112, -89,31,0, 
  /* [3][2][][] */ -122,-65,15, 90,107,-100, 92,-6,-34, 
  /* [4][0][][] */ 11,63,-81, 64,127,-68, 25,18,-127, 
  /* [4][1][][] */ 32,53,112, 16,68,5, -106,31,-102, 
  /* [4][2][][] */ -22,-56,31, -21,21,-104, 33,36,-18, 
  /* [5][0][][] */ 62,13,28, 27,10,-19, -29,-41,64, 
  /* [5][1][][] */ -99,0,19, 121,0,-44, 38,67,107, 
  /* [5][2][][] */ -39,91,3, 46,87,-13, 20,-50,127, 
  /* [6][0][][] */ -86,-68,-110, -69,-4,4, 127,67,-56, 
  /* [6][1][][] */ 84,-47,43, 24,-34,40, 42,65,-14, 
  /* [6][2][][] */ -9,-76,-53, 11,12,72, -21,-80,-82, 
  /* [7][0][][] */ -18,-51,-13, 79,67,-58, -17,61,-4, 
  /* [7][1][][] */ 73,-72,-9, 52,127,15, 35,-49,35, 
  /* [7][2][][] */ 98,-75,107, 6,114,123, 121,89,-45, 
};
const TfArray<4, int> tensor_dimension2 = { 4, { 8,3,3,3 } };
const TfArray<8, float> quant2_scale = { 8, { 0.0020759308245033026, 0.0018573326524347067, 0.0019453417044132948, 0.0019582179374992847, 0.001832225127145648, 0.0020141736604273319, 0.0023176691029220819, 0.0021997340954840183, } };
const TfArray<8, int> quant2_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant2 = { (TfLiteFloatArray*)&quant2_scale, (TfLiteIntArray*)&quant2_zero, 0 };
const ALIGN(16) int32_t tensor_data3[8] = { 1517, -207, 1086, -1694, 1858, -1358, 4965, -1075, };
const TfArray<1, int> tensor_dimension3 = { 1, { 8 } };
const TfArray<8, float> quant3_scale = { 8, { 8.1409052654635161e-06, 7.2836578510759864e-06, 7.6287915362627245e-06, 7.6792866821051575e-06, 7.185196864156751e-06, 7.8987204688019119e-06, 9.0888988779624924e-06, 8.6264089986798353e-06, } };
const TfArray<8, int> quant3_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant3 = { (TfLiteFloatArray*)&quant3_scale, (TfLiteIntArray*)&quant3_zero, 0 };
const ALIGN(16) int8_t tensor_data4[16*3*3*8] = { 
  /* [0][0][][] */ -57,-37,-64,118,-19,-84,100,-39, 98,-20,-98,-19,-6,-102,37,-49, 66,-72,84,77,27,102,75,18, 
  /* [0][1][][] */ 125,-25,-65,106,5,-36,-89,105, 21,16,99,21,-54,-38,-75,-94, -78,53,-109,54,74,86,18,57, 
  /* [0][2][][] */ 37,7,-101,120,65,-73,47,96, 65,13,-73,15,13,-50,-100,-72, -82,3,-91,36,-60,61,49,127, 
  /* [1][0][][] */ -61,121,-87,-73,26,-36,71,53, -86,-36,-55,22,-70,44,-12,-12, 72,119,33,104,88,-23,-82,26, 
  /* [1][1][][] */ 117,-78,-11,90,54,47,13,50, -58,84,91,6,43,-9,-82,-54, -33,-6,103,-14,5,-73,86,105, 
  /* [1][2][][] */ 117,13,86,91,-64,16,-75,-48, -43,90,-43,-13,45,-97,-97,31, -63,53,21,54,102,-59,127,-13, 
  /* [2][0][][] */ -65,103,-100,-59,32,98,-79,-103, 104,10,-24,111,44,-51,-84,83, -36,-77,-68,-101,14,28,6,15, 
  /* [2][1][][] */ 90,87,92,127,46,112,3,-61, 81,-24,-87,-18,48,-50,-60,26, 61,-7,71,103,-4,62,-113,94, 
  /* [2][2][][] */ 26,69,77,-44,81,119,89,14, 51,6,-28,54,60,102,-4,-37, 36,115,64,-49,-73,-55,66,95, 
  /* [3][0][][] */ -68,22,20,7,-17,92,-42,99, -38,-43,26,95,89,86,81,-18, 9,-104,56,12,-26,64,77,-57, 
  /* [3][1][][] */ 2,-104,-41,100,121,-40,6,98, 5,82,120,14,-19,-8,34,-1, -27,-29,-24,27,18,-15,13,16, 
  /* [3][2][][] */ -123,-111,60,87,-81,66,-89,-127, -124,52,74,51,-67,-58,124,-57, -68,49,64,-114,3,68,102,77, 
  /* [4][0][][] */ 24,38,111,1,42,-63,-45,73, -84,-6,46,-21,-77,-62,64,125, 121,-90,106,116,-63,119,-67,117, 
  /* [4][1][][] */ -19,74,-110,5,-98,-8,-108,-86, -63,-36,3,-66,43,87,-87,-7, -26,-109,-58,102,-98,-6,-25,-4, 
  /* [4][2][][] */ 19,-26,16,34,-118,-4,-81,17, 45,30,-98,72,-72,-28,-22,91, -24,73,100,5,127,-18,-38,-79, 
  /* [5][0][][] */ 56,-64,-127,39,87,93,23,89, -76,-85,-116,42,70,81,-93,-80, -49,-9,38,-18,56,-16,-92,46, 
  /* [5][1][][] */ -105,56,49,4,-93,-72,-5,85, -23,-17,9,-62,63,-31,-50,-89, -82,111,-9,18,-68,1,91,54, 
  /* [5][2][][] */ -85,-125,17,96,-47,97,-98,-15, -22,121,31,-69,101,71,96,-17, -105,14,71,61,11,73,83,-8, 
  /* [6][0][][] */ 93,39,59,96,5,51,-57,86, 53,14,35,-79,0,112,-26,-86, -47,86,-6,-28,64,-48,-28,-11, 
  /* [6][1][][] */ 36,33,-15,-68,-125,35,2,-33, 115,2,-70,69,-19,21,96,-69, -67,21,-24,-1,-24,58,9,-65, 
  /* [6][2][][] */ 14,28,21,16,61,100,-54,127, 71,105,-103,-23,-112,120,-53,57, 44,30,-95,53,71,50,-2,109, 
  /* [7][0][][] */ -61,-70,107,-19,-48,99,101,36, 77,-95,-46,38,93,70,109,-112, -73,-85,-55,30,81,38,-33,93, 
  /* [7][1][][] */ 42,0,-71,48,84,87,-5,-46, -38,57,102,51,41,-61,19,-30, 70,-127,-78,98,116,-23,51,-112, 
  /* [7][2][][] */ 63,81,124,20,50,-101,-99,73, -99,-13,-15,86,-72,-49,-42,-23, 47,-4,105,-121,14,2,4,23, 
  /* [8][0][][] */ -48,-42,89,-9,-53,0,14,112, 16,-19,-81,127,80,59,70,92, 31,-74,72,-75,-16,-45,102,65, 
  /* [8][1][][] */ -20,-89,-78,-40,82,-82,53,71, 108,-49,22,1,94,84,-2,93, -15,79,-32,99,-28,4,79,14, 
  /* [8][2][][] */ -25,-46,-90,80,-73,-127,45,-3, -61,36,39,-99,-58,-109,-58,-110, -35,-26,-62,-25,-66,-90,-12,-76, 
  /* [9][0][][] */ -34,-97,39,-24,96,76,-98,-29, 17,122,120,-92,52,48,127,-56, -70,8,91,23,44,-21,51,34, 
  /* [9][1][][] */ -95,61,55,101,99,9,-31,-75, 32,58,8,28,-19,109,72,11, -11,-35,-16,1,82,60,-95,59, 
  /* [9][2][][] */ -1,-1,26,-17,-48,102,29,99, -80,-41,-108,-73,70,-37,53,111, 106,-106,-120,-96,-2,63,5,-46, 
  /* [10][0][][] */ 29,19,47,24,29,-67,-42,62, 126,10,23,57,127,53,116,-70, 31,-5,-10,-70,-7,-16,122,-37, 
  /* [10][1][][] */ 65,74,59,84,-34,-27,-66,51, 25,-125,-58,0,24,-69,-87,-4, -112,69,44,-96,47,-110,5,75, 
  /* [10][2][][] */ -8,-75,-49,109,63,25,29,48, 38,-80,96,-4,-83,12,24,-40, 29,25,95,-95,-58,-105,-41,-92, 
  /* [11][0][][] */ 34,-61,-11,75,4,-65,96,11, -7,94,72,-29,-37,6,46,122, 78,44,-116,103,105,-67,72,49, 
  /* [11][1][][] */ -24,20,-36,62,41,84,32,19, -39,-51,114,38,5,4,70,-89, 84,-41,-28,-45,11,51,69,33, 
  /* [11][2][][] */ -108,-127,-32,80,101,23,37,-114, -78,-11,5,-17,-16,-71,-34,-58, -69,11,45,53,81,-9,118,-56, 
  /* [12][0][][] */ 83,30,-108,-28,35,91,41,-83, -26,16,113,2,51,-85,47,66, 6,66,-52,-58,-28,72,-6,93, 
  /* [12][1][][] */ -80,96,4,57,38,103,2,39, 81,-3,69,-102,13,56,-86,68, 127,27,-118,57,8,-55,-109,93, 
  /* [12][2][][] */ -29,-56,108,20,-18,8,-7,108, -6,-37,-33,20,-69,-29,-41,-58, -30,79,-28,69,-49,-56,-74,-11, 
  /* [13][0][][] */ 2,27,-80,85,-77,-65,10,-75, -54,-25,33,-11,85,23,-72,-61, -4,-67,-68,86,-11,70,98,-13, 
  /* [13][1][][] */ 61,-24,57,-5,19,-11,103,43, -53,41,56,-98,2,79,-24,37, 111,-111,24,-75,-37,-10,127,8, 
  /* [13][2][][] */ 35,35,8,-30,-17,36,119,-1, 36,-23,-20,-40,108,-3,97,-84, -95,17,81,-29,78,43,6,48, 
  /* [14][0][][] */ -1,31,70,40,-69,95,-45,-111, 21,65,-94,-1,106,-24,10,-61, -48,107,68,-80,9,48,30,-8, 
  /* [14][1][][] */ -94,12,88,-61,68,-58,78,8, -98,112,38,-40,-46,-81,26,80, 60,127,-106,86,-40,-111,62,3, 
  /* [14][2][][] */ 60,53,4,101,18,-68,9,79, 74,120,93,-30,68,-98,-68,115, 75,39,115,-24,110,33,21,-55, 
  /* [15][0][][] */ 97,65,-16,77,-74,-86,-112,0, -16,42,-9,-81,61,91,82,26, 82,-56,53,-76,-38,59,-84,51, 
  /* [15][1][][] */ 11,48,6,-91,-87,-31,-6,-16, 14,60,-65,-51,-67,81,-2,127, 31,-53,30,-49,-31,107,69,58, 
  /* [15][2][][] */ -63,4,4,36,49,18,-122,67, 109,99,90,-21,21,31,-49,-21, 75,-8,-81,2,-13,91,64,121, 
};
const TfArray<4, int> tensor_dimension4 = { 4, { 16,3,3,8 } };
const TfArray<16, float> quant4_scale = { 16, { 0.0014155602548271418, 0.0014614366227760911, 0.0013907550601288676, 0.0014883297262713313, 0.0014030521269887686, 0.0014455439522862434, 0.0015824317233636975, 0.0014296467415988445, 0.0014990555355325341, 0.0014345918316394091, 0.0015783457783982158, 0.0015228363918140531, 0.0014267574297264218, 0.0015428875340148807, 0.001495955279096961, 0.001494907308369875, } };
const TfArray<16, int> quant4_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant4 = { (TfLiteFloatArray*)&quant4_scale, (TfLiteIntArray*)&quant4_zero, 0 };
const ALIGN(16) int32_t tensor_data5[16] = { -786, -1372, -1413, -580, 488, -1344, -1361, 1011, 985, -1289, 3744, 1403, -674, 2817, -562, 203, };
const TfArray<1, int> tensor_dimension5 = { 1, { 16 } };
const TfArray<16, float> quant5_scale = { 16, { 1.0206915249000303e-05, 1.0537707566982135e-05, 1.0028056749433745e-05, 1.0731620022852439e-05, 1.0116725206898991e-05, 1.042311305354815e-05, 1.1410143997636624e-05, 1.0308485798304901e-05, 1.08089589048177e-05, 1.0344142538087908e-05, 1.1380681826267391e-05, 1.0980431397911161e-05, 1.028765291266609e-05, 1.1125010132673196e-05, 1.0786604434542824e-05, 1.0779048352560494e-05, } };
const TfArray<16, int> quant5_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant5 = { (TfLiteFloatArray*)&quant5_scale, (TfLiteIntArray*)&quant5_zero, 0 };
const ALIGN(16) int8_t tensor_data6[5*1024] = { 
  -20, -1, -45, 2, -33, 49, -10, -49, 45, -30, -51, 23, -5, -52, -45, -11, -49, 49, -45, 22, 56, -53, 12, -18, 20, 0, -34, -52, 0, -14, 48, -19, -26, 76, -16, 9, -59, 29, 57, 60, -1, 22, 14, -11, -40, -58, 48, -53, 23, 32, 31, -60, 23, -5, 57, 36, 51, -18, -53, 82, -35, 25, 74, -40, -2, 72, -25, 25, 32, -56, -35, 48, -1, 12, 69, 59, 19, 30, -34, -56, 49, 71, 11, 56, 65, 29, 54, 49, 1, -57, -60, 90, 16, -3, -29, -49, 6, 59, 40, 50, 13, 29, -6, 62, -67, 34, 15, 16, 71, -34, 4, -47, -44, 7, 29, -64, 45, -19, -30, -41, -13, 45, 62, -30, 63, 16, 7, -61, -16, 13, -58, 26, 9, 34, -41, -53, -53, -42, -95, 68, 6, 35, -32, 37, -17, 17, 19, -27, 52, -25, -64, -16, 29, 38, -21, -2, 29, 73, 53, -23, 60, 25, 20, 26, 31, -58, 0, 44, -40, 2, -87, -67, -33, -33, 6, -39, 20, 52, -72, 12, -18, 31, -12, 21, 37, 25, 40, 0, 66, -3, -39, 31, -62, 80, 54, 54, -7, 45, -14, -41, 49, -43, -31, 66, -34, 24, 86, 17, -39, 24, -16, 23, -19, 38, 31, 68, 108, -67, -2, 52, -38, 93, 8, -14, 26, 54, -17, 34, 18, -45, 48, 17, 49, -53, 33, -54, 0, 57, 10, 73, 73, 23, 37, 22, 64, 58, 45, -25, -9, 28, -49, 63, -56, -52, -25, -43, -40, -34, -62, -3, -76, -39, -65, -62, 2, -38, 29, 39, -2, -69, 15, -35, 15, -48, -5, -42, 38, 14, -17, -48, -10, 46, 5, 12, -7, -36, 68, 39, -28, 57, -61, 42, 53, 2, 24, 41, -89, 14, -67, 5, -18, 18, -80, 40, 34, 32, 1, 28, -68, 50, 61, -12, 31, 71, -34, -32, -59, -20, 46, -64, -12, -12, -33, -53, -75, 51, 34, -25, -3, -21, 31, -70, -13, 4, -25, 27, -57, -44, -52, -68, -28, 58, -10, 7, -31, -13, 7, 32, 3, -39, -26, -9, 6, -54, 44, 20, 14, -64, 68, -65, -16, -27, -7, 34, -26, -39, 16, 59, -51, 24, -43, 24, 72, -48, 28, 44, 40, -25, 24, 25, -31, -7, -46, 2, -16, -4, -41, -32, 22, 48, -11, -20, -44, -65, 19, 1, 27, -59, -31, 44, 59, 67, -63, -53, 54, 14, -24, -62, -84, 47, 16, 13, 49, -93, -32, -69, -62, -59, 26, 49, -61, -59, -39, 23, 18, -10, 10, -80, 20, 0, -49, -15, 61, -54, -34, 10, 39, -12, -25, -71, -35, 17, -80, -10, 67, -67, -45, -5, 32, -3, -57, -67, -51, 35, 42, -64, 30, -22, -17, -78, 17, -86, -73, 8, 14, -27, -67, 16, -23, 11, -42, -52, -49, -53, 79, -48, 54, 32, -29, 4, 0, -33, 77, 37, -38, -40, 69, -71, -27, -32, -58, 21, -4, -24, 13, 50, 36, 2, 8, -13, -49, 37, 30, 55, -20, 57, -62, -32, -41, -20, 25, 51, 15, 64, 0, 67, 51, 31, 0, -67, 42, 56, -15, 6, 64, 24, 57, 23, -25, -28, -14, 21, -37, -47, 17, 53, -1, -41, 18, -22, 21, -66, -35, 56, -5, 2, -49, -31, -1, -67, 34, -3, -48, 39, -81, -58, -4, -91, 41, -69, 31, 60, -3, 59, -1, -24, -17, -36, 27, -55, -74, 24, -30, 5, 23, -15, -36, 8, -31, -42, 5, 46, 5, 51, 22, -63, 51, 5, -34, -70, -6, -87, -14, 43, -20, 46, 18, 54, -30, 6, 76, -28, 51, -14, -12, 31, 0, -43, -30, 53, -20, -54, -7, -31, -14, 7, 76, 34, -60, 36, 24, -5, -3, 12, 43, 40, 49, 14, -30, -47, 55, -55, -45, 46, 56, -64, -55, -62, 43, -14, -44, 55, -35, 9, -55, -51, -40, -18, -67, -11, -93, 2, 40, 23, -14, -12, -29, 51, -49, -55, -9, -18, 5, 44, 50, 33, 25, -72, 9, 29, 22, 15, -22, 47, 63, -21, -36, 52, 48, 4, 31, -13, 33, -57, -29, -42, -41, 41, -18, -25, -11, 28, -38, 26, -9, 76, -73, 54, 43, 40, 17, 24, 9, -1, 23, 7, 21, -15, -5, 37, -6, -50, 7, -62, 64, -10, -77, -28, 1, -67, 4, 48, -10, -80, -45, -66, 25, 13, 26, 35, 13, 53, -34, 54, 7, -51, -49, 63, 0, 65, -3, 55, -38, 81, 92, 38, 61, 61, 0, 2, -35, -45, 27, -29, 1, 22, -43, -48, -25, -16, -22, -40, 78, 41, 35, -17, -17, 11, 70, 58, 55, -45, -36, -12, 51, -40, 21, -7, 62, -21, 6, 39, -19, 1, -55, -54, -37, -41, -46, 50, -67, -8, 17, 19, -43, 35, -20, -79, -49, -65, -70, -16, 13, -55, -49, 53, 3, -15, 21, 41, -25, -1, -53, 4, -71, -7, 81, -35, -37, 46, -44, -1, 6, 8, -15, 58, -82, -24, -53, 80, -20, -3, -36, -53, 29, -40, -15, 52, 3, -20, -60, -50, -62, -24, 21, 2, 39, -36, -40, 44, 4, 55, 55, 1, 62, 26, -12, 63, 111, -27, 35, -14, 27, 8, -48, 29, -81, -15, -59, 37, -56, 21, -84, -2, 106, -32, -74, -40, -22, -18, 15, -91, 39, -2, -55, 58, 35, 34, 36, 33, -1, 46, -57, 51, -80, -99, -32, 80, -43, 65, 66, 17, -27, -46, -22, 44, -2, 1, -15, 25, 55, -28, -7, -64, -65, 49, 6, 68, -47, 0, 60, 61, 45, -33, -27, -21, 32, 33, -50, -27, -42, 4, -7, -25, 26, 26, -8, 20, 18, -51, -1, -23, 15, 10, -34, -49, -22, -58, 49, 27, 61, -73, 56, 8, -94, 49, 54, 57, -50, 5, 11, 39, -13, -9, 70, -25, 3, -7, 41, 37, -48, 53, 38, -63, -71, -5, -34, -26, 46, 65, -41, -14, -22, -1, 65, -34, -24, 7, 44, -48, -15, -18, 28, -25, -20, 6, -27, -38, 54, -46, -41, -59, 83, -36, 32, -80, -23, -85, -10, 24, 17, 14, -86, 12, 28, 28, -76, -41, 30, -41, 17, 65, -71, -66, 
  32, -65, 33, -6, 20, 6, -63, 5, -67, 12, 10, 62, 22, 44, -6, 55, -26, 20, -19, 11, -17, 38, 49, 32, -30, 45, 15, 40, 49, -86, -28, -18, -25, -37, -26, -5, 54, 10, -53, 43, -27, -30, -32, -49, 64, -28, -43, -19, 38, 50, -60, 12, 12, -5, -17, 41, -81, 34, -29, -26, 34, -52, -38, 71, 9, 22, 20, -61, 63, 40, -20, -37, -109, -20, 6, -81, -50, -65, -33, 46, 57, 13, 7, 65, 10, -13, -26, -5, 22, 65, 30, 43, 15, 39, -16, 38, -55, 26, -27, -63, 31, 28, -22, 21, 1, -53, -55, -34, 12, 2, -34, 38, -32, 3, -67, -20, -3, 2, 70, 65, 13, 48, -26, -47, 65, -11, -31, -63, -26, -20, 56, -1, -49, 48, 24, -18, -7, 21, -28, -24, -70, 41, -32, -63, -21, 40, 21, 56, -72, -25, 66, -51, -78, 2, -24, 49, -33, 1, 43, -20, 59, 23, -58, 30, 29, -9, -33, -79, 21, 47, -46, 33, -26, 10, 46, -46, -67, -62, -13, -38, 0, 63, 67, 18, 30, 60, -74, -92, 43, -64, 33, -45, -52, -55, -54, 0, -66, 1, 52, 8, -52, -44, -96, -7, 58, -5, -30, -3, 59, 8, -26, -16, -4, -67, -30, 40, -36, 64, 29, -89, 54, -59, -41, -55, -56, -75, -47, 44, -33, 26, -44, -57, 2, -5, 9, 38, -20, 14, -24, 17, 41, 54, 54, -1, 9, -60, -44, -29, 30, -20, 6, 6, -22, -59, -51, 38, -21, 10, -9, 24, 15, 56, 38, -62, 27, -37, -34, -10, 23, 2, -32, 57, -1, -14, 51, 7, -50, -55, 38, -24, 8, -71, -61, -24, 41, -77, -25, -56, 29, 27, -41, -5, -5, 6, -58, -22, -1, -16, 10, 13, 25, -69, 38, -38, -41, -33, -16, -35, 53, -68, -8, 30, -99, -28, -58, -34, 22, 22, -1, 34, 61, 47, 65, -45, 30, 3, 49, -42, 17, 32, 17, -23, 70, -91, -5, 34, -44, -68, 51, 41, 52, -49, 72, -36, -87, 53, -81, -28, 42, -16, -92, -40, -6, -63, 3, -51, -49, 67, 35, -12, -34, 68, -8, -57, 11, 23, -77, 43, -59, 56, 49, 65, -37, 44, -50, -65, 21, 15, -43, 54, 66, -6, -18, -37, 18, 5, -59, 28, -67, -9, -59, 14, -47, 4, -101, -29, 28, -4, 20, 32, -16, 35, 57, 30, 7, -45, -72, 58, -13, -35, -100, -36, 79, -60, 86, -17, 10, -12, -42, 61, -53, 51, 38, -46, -20, -48, -61, 55, 79, 18, 42, 60, -15, 30, -48, -46, -12, -61, -44, -55, -3, 0, -84, -83, 76, 21, -17, 39, -4, -41, -54, 64, 16, 44, 59, 46, 26, 51, -105, 75, 53, -66, -45, -16, 48, 28, 69, 29, -14, -48, -42, 32, -27, -36, -27, -88, 27, -48, -31, 69, -70, -37, -67, 59, -33, 42, -8, -71, -21, 38, -22, 56, 36, 10, -87, 33, -2, 20, 50, -1, -61, -63, 28, -63, -60, 5, 23, 38, -5, -31, -50, -10, 25, -77, -4, -41, -14, 41, -31, -73, 20, -56, 18, -44, -51, -26, -19, -23, 2, 67, 10, -29, -3, 1, 54, 35, -50, -23, -31, -41, 23, -46, 71, 30, -24, 21, 5, -63, 34, -2, 46, -88, 46, 4, -8, -17, 4, 55, -14, 24, 58, 52, 47, 58, -20, 62, 66, -61, 8, -57, -21, -57, 70, -6, 12, 78, 60, -3, -11, -56, 16, 10, 60, -53, 21, 26, 10, 62, 7, 56, 28, -45, -51, 49, -49, -9, -46, 31, 35, -52, 0, -25, -41, -63, -67, -48, 41, 54, 10, -15, -31, -57, 55, -32, -63, -71, -25, -27, -63, 20, -13, 8, -14, -20, -55, 43, 27, 26, -25, -39, 5, -53, -11, -45, -64, -19, 19, 14, -44, -63, -46, 9, 39, -66, -22, -46, -92, 67, 53, 17, 36, 8, -56, 39, -22, -56, 43, 49, -57, -28, -53, -47, -89, -27, 51, -30, 50, 7, -41, -43, -66, -16, -1, 19, 2, 43, -61, -37, -33, -35, 34, -28, -95, 33, 43, -24, -32, -16, -58, 9, -31, 39, 82, -22, 31, -79, -30, 4, -43, -82, 16, -16, -5, 49, 54, -25, 27, 48, 44, -58, -58, 52, 11, 78, 60, -10, -29, -48, -44, -38, 34, -56, 70, 19, 4, -7, 19, -30, 47, -64, -79, -23, 48, -30, -104, -6, -56, 12, -66, 52, 49, -58, 52, -14, -14, -28, -1, -19, 15, 19, -28, 27, -51, -43, 7, -30, -28, 29, 61, 19, -68, 68, 64, -83, 17, -54, -35, -15, -96, 19, -20, 44, 15, 55, -29, 18, 32, -70, 82, 96, -103, -64, -4, -46, 17, -93, -2, 34, -61, -13, -84, -26, -37, -86, -65, -18, -71, 106, 18, -8, -6, -69, 26, -53, 58, -26, 48, -61, -11, -4, -119, 23, -51, -81, 2, 11, -37, 62, 15, -51, 50, 3, 1, -55, -53, -40, -36, 49, -56, -27, 49, 45, 41, 14, -63, 69, -16, -36, -85, -11, 59, -73, 67, -33, -83, 65, 2, -14, -68, -7, -29, 48, 42, -74, -12, 68, -22, -26, 1, 44, 37, 38, -102, -71, -39, 18, 12, -39, -38, -16, 27, -35, 74, 3, -79, 43, -47, 74, -51, 74, -10, -68, 44, -57, 25, 13, -45, -10, -76, 27, 11, 24, 32, -92, -82, 15, -102, -60, -65, -43, -105, -5, -58, 29, -76, -66, 18, 1, 0, -50, -30, 4, -72, -25, -104, -84, -46, 30, -78, -62, -100, -73, -127, -64, -20, -9, -106, -88, -70, -50, -16, 42, 85, 32, -77, 15, 5, -19, -75, -69, -45, 78, -44, 13, -79, 22, -48, -59, -31, -65, 39, -40, -81, -25, -30, 10, -67, 24, -84, -41, -19, 4, -64, -8, -72, -31, -62, -24, 1, -65, -3, -54, -108, 1, -1, -23, -58, -90, -70, -27, -15, -80, -93, 11, -55, -47, 5, 4, -48, -35, 10, -64, -24, 30, -86, 19, -16, -91, 11, 20, -60, -48, -30, 5, -16, 96, 9, -28, 2, 46, -64, -34, 38, -20, 42, 28, -48, 37, -24, 27, 46, 0, -57, 17, 
  -70, 53, 32, 13, 32, -8, 11, 52, 47, -37, 25, -72, 65, -22, 0, -12, 10, 64, 65, 37, 13, -47, 40, 28, -32, -6, -13, -72, 60, -11, -35, -33, 0, -29, 28, -61, -35, 18, 36, 46, -50, 27, 6, -52, -25, -8, -64, 30, -43, -4, 56, -25, 24, -32, 48, 9, 42, -37, 41, 54, 23, 91, -23, -18, -9, 14, -68, -56, -15, 4, 29, 26, -23, 26, -14, 29, 25, 74, 34, -32, -36, 18, -61, 20, 31, -58, -58, -41, 43, -72, 59, 46, -15, 50, -9, 45, -29, 46, -32, 54, -37, -20, 53, 72, 72, 25, -37, 39, -19, 4, -60, 28, 40, -49, -10, 39, 32, -55, -35, 55, -51, 50, -58, -9, -16, -47, 32, -71, 61, -22, -20, -68, 9, 32, -58, -22, 28, 36, 26, -15, 19, 71, -44, 30, 46, 7, 33, 31, 25, -2, 36, 21, -44, 31, -1, -48, -55, -41, 26, 56, 37, 26, -24, -17, -41, 62, -52, 65, -56, 43, 20, 6, -14, -46, 14, 43, -43, -47, -55, 33, -37, 29, 2, 4, -9, 29, 48, 18, -36, -81, -65, -18, 53, -65, -60, -66, -45, -15, -31, 39, -30, 8, 23, 21, -15, 1, -58, 61, -66, -62, 65, 62, 33, 69, 23, -43, -74, 59, -66, -90, -5, 17, 45, 15, -22, -13, -29, -68, 56, 19, -18, 59, 89, -12, -45, 62, -18, 28, -32, -8, 53, 18, -18, -16, 42, 59, -47, -54, 76, -53, 76, -24, -59, -33, 49, -65, -60, 51, 10, 47, -28, 64, 35, -39, -73, -37, 65, -70, -16, 74, -56, 8, 1, 16, 44, 50, 20, -35, 11, 53, -59, 42, -28, 1, -46, -11, 23, 0, -20, 60, -48, -37, 60, 38, -25, 21, 37, -21, -61, -25, -2, -70, -22, 73, 73, 32, -30, -52, 49, 58, 54, -31, 19, 48, -85, 18, -39, -105, -52, -27, 58, 5, -25, -28, 32, 55, 58, -44, -53, -51, 17, -102, -23, -30, 26, 61, -57, 13, -9, -40, -49, -44, 43, -48, -71, 70, -61, -39, -36, -85, -33, -57, -18, -21, 24, -37, -36, -5, -58, 74, 9, -40, 31, -59, 72, -58, 19, 62, -65, -68, 7, 63, -77, 21, 17, 58, 48, -50, 55, -26, 23, -19, -32, 17, 24, 10, -31, 19, 3, -33, 24, -61, 20, 15, -30, 4, 11, 4, -75, -4, 41, 56, -58, 20, 40, -43, -57, -18, -21, 17, 30, 42, 59, 16, -79, 4, 8, 29, -65, 32, -9, -19, -36, 9, 46, -27, -29, 61, -53, -85, -62, -45, -8, -45, -20, 42, 0, 49, -60, 63, 55, 39, 27, 49, -27, -46, -68, 25, -24, 48, -56, -20, 28, 27, -39, 15, -6, -76, 41, 17, 60, -91, -84, -12, -22, 31, 29, 28, -55, 52, -44, 42, -28, 44, 44, -68, -32, -51, -67, 44, 6, -24, -64, 6, -11, -53, -20, -58, -27, 50, -45, -45, 38, 8, -37, 41, 15, -57, -4, 24, 63, -25, 35, 10, 11, -11, 15, 23, 53, -58, 47, 3, -35, 20, -61, -62, 6, -63, -17, -14, 5, -12, 61, 77, 35, 9, -59, -8, -52, -8, 56, -32, 63, -31, 5, 34, 92, 63, -4, 2, 53, 49, -52, -1, -5, -43, 31, 12, 77, -2, -46, 72, 79, 40, 73, -30, -3, -48, 4, 1, -41, -12, -18, 5, 5, -7, -48, 12, -4, -5, 92, 89, -39, -32, -50, 44, 22, -66, -70, -58, -2, 51, -42, -44, 47, -29, -85, -53, 25, -3, -46, -26, -68, -42, 29, 5, -55, 51, -21, -73, -22, -52, -9, -52, -15, -91, -77, -43, -54, -44, -41, 9, -29, 19, 57, -33, -9, 30, -31, 38, -2, 14, 64, -68, 29, 19, -55, 3, 30, 46, 18, 12, -64, 32, -40, -45, 35, -7, -38, 44, -47, -17, 13, 11, -1, 32, -36, 6, 40, -70, -12, -53, 56, 38, -65, -24, 23, -43, -74, 61, -51, 63, -55, 30, 4, -42, -24, 14, 29, 38, 8, -56, -41, 31, -35, 32, -60, 1, -73, 33, -22, -24, -8, 45, -82, -72, -61, 17, -11, 32, -53, -36, -41, 43, -75, 28, -22, -44, 58, 37, -43, 11, -21, 3, -44, -21, 43, 53, 23, -18, 38, 23, -43, 39, -64, -28, -9, -9, -42, -17, 58, 27, 39, 55, -57, 29, -11, -63, -5, -5, -7, -50, 19, -118, -36, -38, 28, -60, -20, -64, -1, 17, -44, 42, 17, -13, 26, 10, -48, 4, 42, 34, 14, -66, -41, 16, 13, 15, -24, -32, -28, 4, 50, -74, -35, 49, 52, 20, 25, -8, -5, -73, -64, -30, 29, -38, -33, 48, -61, -88, 28, 30, -5, -43, 42, -3, -48, 17, 28, 19, 46, -57, 24, 62, 19, -24, 63, -38, -43, -68, 12, -55, -26, -47, 19, -16, 7, 0, -39, -22, -7, -63, -3, -31, 33, -4, -22, 29, -74, -20, -54, -32, -14, 13, -27, -52, 18, -78, -75, 15, -56, 21, -26, -43, 30, 8, -37, -8, 31, -42, 20, -32, -40, -12, -56, -57, 28, 45, 22, -42, 19, -49, -63, -10, -4, -69, 40, -57, -74, -26, 24, 6, -39, 73, -18, -46, 20, -27, -40, -52, 72, -74, -3, 66, -27, -72, -40, -114, 57, 12, -59, 34, -24, 38, -40, 11, -57, -25, -46, -28, -26, 26, 51, 14, 17, 45, 31, -71, 35, -18, 61, 6, 61, 27, -51, -48, -21, -53, 33, -59, -33, 71, 40, -42, 33, 64, -16, -28, 42, 11, 55, -6, -21, -42, 20, -31, 17, -5, -3, 7, -61, -69, -31, 48, 26, 13, 70, 11, -93, -6, 34, -3, 71, -55, 68, 28, 76, -35, -69, 29, -7, -13, 3, 31, -78, 71, -29, 24, 76, 10, -24, 30, -25, 23, 46, 64, 66, 33, 68, -47, -11, 29, 46, -79, -39, -1, -16, 45, 22, 30, 14, -35, -45, 76, 13, 15, 20, 42, 47, -43, 38, -3, -37, 43, 51, 47, -38, -38, -49, 9, -4, 40, 20, -36, 1, -67, 28, 31, 28, -62, 31, 37, 26, 66, 58, -47, 56, -7, 18, -56, 48, -22, 59, 83, 
  -60, 1, 29, 24, -2, 12, 41, -63, -57, -39, 34, 39, 19, -47, -15, 33, 44, -57, -17, -57, 50, -41, 3, 22, -86, 1, -57, -67, -12, -75, -33, -43, 19, -56, 57, -36, -62, -5, 13, -3, 34, 21, -35, -1, 31, -56, -16, -22, 51, 3, -29, -45, 49, 39, 65, -9, -2, -44, -26, -7, -64, -5, 31, -36, 52, -29, 58, -32, -27, 68, 36, -22, -64, -46, -12, -26, -30, -54, 37, 9, -21, -33, 67, -59, -47, -12, -56, -66, -107, 54, -17, 30, -30, -75, 1, 56, 44, -11, -58, 48, -33, 30, 58, 41, 32, -39, -90, -60, 19, -89, -60, 15, -71, -30, 8, 11, -16, -59, -44, 25, -37, -45, 46, -20, -24, -1, 65, 12, 64, 13, -64, -10, -57, -60, 54, 68, -20, -18, 14, -80, -38, 52, -43, -28, -36, -62, 27, -67, -64, 44, -11, -26, -92, 1, 33, 6, 37, 42, 8, 38, 37, 13, 12, -5, -72, 36, 1, -81, -61, 0, 2, -14, -28, -37, -72, 67, 62, -32, -42, -42, -57, -36, -2, 1, 44, -20, -24, 1, 9, 5, -70, 13, 59, -13, -41, 16, -23, -14, -12, -67, 12, -14, -65, 61, -25, -7, -61, 23, 1, -16, 27, -59, -28, -54, 65, -65, -1, 10, -87, -44, -34, -9, -19, 19, -37, -9, 14, -46, 57, 46, -44, 18, 29, -4, -6, -55, 70, -48, 21, -52, 12, 56, 48, 66, -53, -2, 23, 57, 12, 3, 64, -35, 0, 36, -53, -17, -53, 25, 29, -35, 8, 4, -9, -48, 4, 40, -79, -16, 28, -9, -91, -58, 18, 41, -69, 15, -23, -64, 61, -59, -65, -28, -4, 18, 36, -7, 0, 33, -50, -73, 59, 41, 12, 54, -71, 64, 11, 33, -40, 48, -3, 30, -85, 48, -17, -68, -36, 16, 7, 59, -11, 39, 109, -7, -9, 47, 14, -40, -80, -26, 25, -50, -39, 38, -7, -55, -3, 45, 17, -56, 10, 52, -71, 1, -37, -18, 64, -71, -44, 83, -52, 45, -32, -43, 15, -54, -36, 62, 61, 26, -47, 46, -15, -10, -12, 23, 27, 57, 10, -7, -17, 52, -20, 20, 45, -4, -47, -51, -43, -41, -47, -40, -33, 27, 3, -30, 28, 60, -56, 30, 0, 6, 8, -35, -59, 36, 11, 44, 59, -60, -30, 36, 15, -50, -95, 28, 27, 20, -11, 41, -12, -89, 3, -25, 20, -6, 28, -62, -53, 8, -84, -27, 41, 22, -54, -27, 6, -38, -36, 58, -34, 59, 53, 69, -34, 13, -13, 40, 61, 33, -25, -63, 42, -36, -21, 46, -50, 31, 27, -36, 39, 77, 59, -53, -59, 4, 6, -42, 39, -23, -44, 40, -37, 67, -32, -41, -43, 31, -21, 53, 25, -10, 48, 25, -23, -39, -35, 11, -14, 65, 23, -44, -47, 14, -33, -63, 57, 57, -40, 19, 48, -19, 33, 9, 23, -19, 63, 53, -43, -1, -5, -22, 35, -26, 15, 52, -58, 40, -10, 26, 29, -2, 46, 22, 8, 66, -12, 33, 49, -31, 19, -61, -15, 20, -57, -55, -45, -31, 52, 1, -78, -67, -2, -107, 4, -18, -70, -75, 24, 26, 0, -47, 1, 30, -43, -49, -16, -56, -29, -70, -48, -88, -86, 13, 47, -2, -54, 41, 15, -14, 24, 43, -18, 11, 25, -27, 46, -15, -52, 31, 50, -56, 55, 56, 38, -9, -17, -11, -60, 65, 35, -9, 39, -19, -56, 52, 33, 50, 52, 67, -5, 76, 0, -84, 36, -47, -35, 2, 39, 19, 28, 22, -32, -56, 16, -62, 70, 47, 47, 42, -22, 63, -88, -46, 50, 65, 61, -51, -19, 33, 22, -36, -19, -31, 70, 14, 4, -9, -58, -40, 59, -67, -70, 2, 42, 50, 14, 36, 43, -17, 42, 22, -72, 64, -48, -37, 62, -18, 18, -29, -61, 8, 5, -16, 58, -8, 24, 12, 4, -80, -79, -57, -46, -105, -31, -57, -48, -86, -6, 18, 73, 43, 28, -65, 24, -56, -68, -62, -48, 11, -39, -24, 48, 54, -64, -47, 69, -31, -17, -12, 80, 4, -69, 36, -22, -49, -90, 18, -67, -23, 27, -14, -27, -31, -79, -12, 81, -30, -56, 13, 30, -36, -55, -69, -16, 0, -9, 32, 25, 45, -65, -37, -44, -13, -20, 78, 16, -27, 8, 38, 4, 32, 62, 29, 43, -4, -45, -1, 81, -28, -57, 94, 70, -60, 44, -23, -25, -37, -39, -46, 18, -12, -7, -25, -13, 20, 3, -3, 24, -58, -11, 42, -51, 35, -47, -22, 14, -57, -45, 29, -77, 29, -50, -29, 56, 41, -39, -37, 17, 29, -56, -56, -28, -58, -24, -33, 10, -49, -24, -18, -29, -81, -27, 52, -23, 1, 49, -43, 68, -10, -36, 55, 98, -59, 67, 29, 17, 0, -26, -19, 1, -5, -63, -64, 57, -13, -43, 41, 60, 17, 78, -40, -80, -49, -32, -21, 33, -21, -104, -59, -37, -79, -10, 29, 60, -29, 56, 39, -80, 19, -24, -103, -8, 31, -9, 39, 9, -57, -58, -35, 99, -50, -26, 46, -21, 38, -90, -56, -25, 19, -60, -2, -24, 23, 1, 27, -22, 18, 74, 83, -83, 17, -55, -67, 5, -33, -69, -5, -24, 17, 22, 76, 95, 29, -46, -5, -19, 79, -7, -58, -22, -17, 60, 65, 27, 21, -23, 17, 73, -78, 34, -42, 45, 15, 58, -32, 43, 17, -68, -43, 52, -29, -29, -17, -24, -43, -12, -60, -34, 20, -95, -32, -30, 40, 39, -43, 27, 29, 59, 83, -21, 51, 53, -17, 14, -31, -23, 10, -81, 44, 41, 38, -111, -23, -78, -59, -23, -67, 66, -24, -92, 9, -66, -96, -28, 5, -78, -19, -14, 4, -4, 40, -4, -57, 85, 17, -113, 26, -41, -119, -41, -21, -113, -68, -14, -42, -23, -11, -82, -68, 64, -70, -56, 1, -84, -12, -83, -110, -38, -85, -38, -56, -40, 34, -38, 8, 4, -23, -24, 82, -115, -112, -6, -93, -9, -25, -36, 11, -73, 32, 6, -45, 53, -94, -69, 54, 16, -29, 26, -67, 28, -74, 50, 5, 13, 40, 10, 39, 56, 49, 10, -16, -55, -86, 
  -3, 57, 43, 2, -44, -33, 17, 65, -16, -54, -40, -16, 43, 47, -73, -54, -13, 7, 4, 67, 52, 19, -68, -21, 14, -36, -37, 2, -21, 4, 37, 9, 9, 5, -46, -50, -70, 20, 22, 7, 81, 45, 57, -37, 42, 37, -63, 54, -7, -31, 43, 39, 22, -43, -31, 34, 42, 52, 44, -23, 8, 42, 16, -75, 16, 58, 39, -53, -78, 41, 17, 54, 35, -85, 9, 31, -72, -53, 39, -49, -53, 64, -4, 5, -73, 18, -23, 17, 18, -22, -9, 36, -5, -1, -35, -7, -29, -52, -58, 39, -33, -9, -46, -13, 59, -24, -34, 11, 37, -66, 57, -23, 31, 6, 42, -20, -87, 3, 59, 4, -72, -61, -51, -9, -60, 43, 83, 4, -30, 26, 36, -22, -22, -29, -22, 18, 38, -23, 92, -27, 31, -15, -57, 23, 50, -14, 13, -59, 26, -17, -58, 45, 98, 9, 37, 93, 40, -19, 40, 29, 33, -38, -39, -12, 66, 47, -27, 1, -7, -38, 22, 49, 70, 14, -34, 29, -64, -34, -12, 37, -63, -64, -76, -54, 43, 9, 77, 37, 39, -32, 12, 10, 34, -45, -23, 2, 4, -25, -69, -62, -60, -11, -31, -65, 37, -25, 16, 53, 8, -52, 33, 27, 18, 35, -41, -83, -73, 18, -42, 10, 28, 28, -38, -24, -50, -22, 23, 55, 52, 60, 38, 21, -71, -39, -23, 27, 24, -43, -22, 24, -41, -5, -58, 36, -13, -70, -80, -14, -57, -42, 3, -29, -73, -53, 66, -29, 32, 38, -5, -10, 16, 55, -7, -6, -20, -12, 44, 37, 16, -56, 2, -15, -11, 35, -48, -42, 8, -66, -5, 74, -15, -41, 49, 31, -2, -30, -37, -12, 48, 7, -56, -40, -94, -54, -53, -51, 26, -28, -23, 59, 36, -7, 3, -9, -48, 14, -55, -13, 35, 47, -70, -48, 9, 30, 22, 18, -23, -1, -11, -14, -49, 58, -65, -20, -25, -75, 42, 9, -78, -45, -65, 6, -11, 19, -25, 0, -54, 45, 16, -73, -38, 59, -46, 38, 16, 4, -59, 51, 37, 16, 16, -36, -31, -27, 15, 53, -39, 39, -41, -5, 48, 2, 8, -52, -5, -13, 37, -77, 36, -27, 29, -4, -54, -73, -78, -21, 17, 43, -29, -45, 15, -23, 60, -41, -66, 8, 24, 11, -50, -52, 10, 34, 45, 30, 38, -31, -57, -60, 66, 53, -51, 49, -41, -9, -77, 13, -22, -57, -20, 53, 108, 39, 29, 50, 31, -50, -21, -34, 43, -4, -64, -4, 36, -70, 47, 55, -1, 21, 57, 63, 88, -65, 26, 25, 4, -47, 65, 40, -45, 43, 52, 19, 13, 64, 48, -28, -13, -12, 57, -42, -27, -43, -17, -40, -61, -53, -1, -6, -33, 46, -43, -21, -48, 21, -45, -41, -22, 50, 19, -4, -7, -62, -23, -42, -59, 46, -1, 56, -20, -68, -79, 28, -20, -67, -68, 37, -70, 54, -58, 17, 27, -22, -30, -18, -59, -6, -1, -43, 26, -33, -78, 44, -66, 21, -63, -18, -16, -42, 18, -58, -15, 10, 4, 40, -46, 35, -5, -47, 41, 10, -103, -1, 67, -39, -28, 20, 49, -36, 23, 54, -25, 55, -46, 57, 43, 30, 35, 1, 14, 17, 32, 26, 13, 13, -56, 50, 12, 34, 12, 55, -41, -11, -33, 31, 25, 8, -2, 57, 41, -2, -6, -13, -51, -69, -13, -2, -17, -31, -11, 32, 47, -49, -27, 12, 53, -63, -28, -20, 13, -76, -48, -69, -36, -46, 25, 24, 36, -70, 27, 70, -15, 39, 35, -10, 18, 48, -22, -48, 0, 46, -77, -66, 7, -62, -56, -8, 21, -22, 19, -41, -54, 55, -43, -5, -38, -58, -2, 49, -20, 57, -40, -26, -8, -75, -40, 43, -1, -31, -53, 21, -60, 52, -14, -18, -38, 13, -28, -53, 94, -87, 53, 54, -34, 29, -31, 57, 33, -12, -16, 64, 8, -1, -27, -5, 0, 31, 44, 16, -16, 70, -3, 50, -31, 33, -68, 19, -16, 15, 11, -20, 76, 1, -48, 58, -25, 58, -42, -58, 9, -58, -103, 8, 48, -93, 48, 63, -11, 50, -28, -22, 13, -45, 46, 70, 9, -11, -23, -36, -79, -66, 67, 68, -1, 63, -13, 20, -23, -31, -15, 26, -29, -52, 18, 53, -111, -24, 14, -40, 9, -8, 12, -70, -58, -57, -13, -63, -20, -10, 5, 47, 23, -88, -39, -65, -33, -5, -13, -49, 26, 8, 4, 61, 32, 25, -109, -30, -2, -46, -21, -21, 77, -12, -50, 35, -14, -3, 52, -33, -52, -53, 36, 54, -11, -24, 16, -12, 36, 1, -33, -37, 15, -30, 2, 14, 43, -19, -28, -43, -3, -69, 86, 1, 24, 50, -27, 79, 44, -49, -36, -29, 69, -98, -25, -11, -96, -41, -22, 3, -24, 16, 86, 50, -39, -59, -25, -48, 72, 37, 14, 23, -49, -13, 61, -63, 13, 84, 34, 11, 89, -36, 41, 50, 59, 17, -89, 50, 4, -91, 10, 24, 8, -2, 30, 18, -13, -54, -40, 13, 17, -54, -49, -51, -17, 27, -10, 7, -16, 76, 11, 11, 48, -34, -35, -45, 85, -70, -1, -17, -4, -64, 75, -82, 0, 22, -20, -43, -32, -44, -72, -35, 52, 30, -66, -28, -72, -35, 32, -13, 89, -13, 18, -26, -67, 46, 47, -14, 4, -58, -57, 13, 12, -48, 11, -52, -8, 38, 70, -23, 56, 53, 22, 35, -18, 21, -20, 64, -68, -17, -17, -13, 26, 17, 77, 78, 22, 25, -12, -8, -12, 33, 71, -17, -52, 9, 55, -87, -40, 12, 9, 48, -11, -37, -26, -21, 81, -40, 31, -34, -8, -22, 28, -81, 67, 37, 65, 98, 5, 21, 91, -37, 98, 40, -2, -30, 10, 52, 37, -93, 43, 77, -31, 6, 76, -28, -24, 33, 59, -27, 56, -19, -2, 54, 60, -2, 5, 4, 55, 15, 15, -31, 50, 74, 21, 48, 75, 74, -22, 23, -29, -98, 28, 30, 44, 25, 35, -5, 1, -21, 101, -55, 77, -15, -48, 6, 2, -89, -23, 91, 5, 59, 22, -25, 24, 76, 54, 27, -13, -32, -24, -29, 73, 10, -22, -46, 
};
const TfArray<2, int> tensor_dimension6 = { 2, { 5,1024 } };
const TfArray<1, float> quant6_scale = { 1, { 0.0011028157314285636, } };
const TfArray<1, int> quant6_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int32_t tensor_data7[5] = { -1232, 241, 1099, -218, -829, };
const TfArray<1, int> tensor_dimension7 = { 1, { 5 } };
const TfArray<1, float> quant7_scale = { 1, { 8.996786164061632e-06, } };
const TfArray<1, int> quant7_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const TfArray<4, int> tensor_dimension8 = { 4, { 1,32,32,8 } };
const TfArray<1, float> quant8_scale = { 1, { 0.0072105126455426216, } };
const TfArray<1, int> quant8_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const TfArray<4, int> tensor_dimension9 = { 4, { 1,16,16,8 } };
const TfArray<1, float> quant9_scale = { 1, { 0.0072105126455426216, } };
const TfArray<1, int> quant9_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const TfArray<4, int> tensor_dimension10 = { 4, { 1,16,16,16 } };
const TfArray<1, float> quant10_scale = { 1, { 0.0081580141559243202, } };
const TfArray<1, int> quant10_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const TfArray<4, int> tensor_dimension11 = { 4, { 1,8,8,16 } };
const TfArray<1, float> quant11_scale = { 1, { 0.0081580141559243202, } };
const TfArray<1, int> quant11_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<2, int> tensor_dimension12 = { 2, { 1,1024 } };
const TfArray<1, float> quant12_scale = { 1, { 0.0081580141559243202, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<2, int> tensor_dimension13 = { 2, { 1,5 } };
const TfArray<1, float> quant13_scale = { 1, { 0.02789275161921978, } };
const TfArray<1, int> quant13_zero = { 1, { 87 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<2, int> tensor_dimension14 = { 2, { 1,5 } };
const TfArray<1, float> quant14_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfLiteConvParams opdata0 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs0 = { 3, { 0,2,3 } };
const TfArray<1, int> outputs0 = { 1, { 8 } };
const TfLitePoolParams opdata1 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs1 = { 1, { 8 } };
const TfArray<1, int> outputs1 = { 1, { 9 } };
const TfLiteConvParams opdata2 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs2 = { 3, { 9,4,5 } };
const TfArray<1, int> outputs2 = { 1, { 10 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 10 } };
const TfArray<1, int> outputs3 = { 1, { 11 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 11,1 } };
const TfArray<1, int> outputs4 = { 1, { 12 } };
const TfLiteFullyConnectedParams opdata5 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs5 = { 3, { 12,6,7 } };
const TfArray<1, int> outputs5 = { 1, { 13 } };
const TfLiteSoftmaxParams opdata6 = { 1 };
const TfArray<1, int> inputs6 = { 1, { 13 } };
const TfArray<1, int> outputs6 = { 1, { 14 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 8192, (TfLiteIntArray*)&tensor_dimension0, 3072, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 216, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant2))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant3))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 1152, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant4))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant5))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 5120, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 20, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension8, 8192, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 8192, (TfLiteIntArray*)&tensor_dimension9, 2048, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension10, 4096, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 4096, (TfLiteIntArray*)&tensor_dimension11, 1024, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 1024, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 1024, (TfLiteIntArray*)&tensor_dimension13, 5, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 5, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_SOFTMAX, },
};
static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {
  return &tflTensors[tensor_idx];
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {
  return &tflEvalTensors[tensor_idx];
}

} // namespace

TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 15;
  for (size_t i = 0; i < 15; ++i) {
    tflTensors[i].type = tensorData[i].type;
    tflEvalTensors[i].type = tensorData[i].type;
    tflTensors[i].is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    tflTensors[i].allocation_type = tensorData[i].allocation_type;
#else
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;
    tflEvalTensors[i].dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    if(tflTensors[i].allocation_type == kTfLiteArenaRw){
      uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

     tflTensors[i].data.data =  start;
     tflEvalTensors[i].data.data =  start;
    }
    else {
       tflTensors[i].data.data = tensorData[i].data;
       tflEvalTensors[i].data.data = tensorData[i].data;
    }
#else
    tflTensors[i].data.data = tensorData[i].data;
    tflEvalTensors[i].data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
    tflTensors[i].quantization = tensorData[i].quantization;
    if (tflTensors[i].quantization.type == kTfLiteAffineQuantization) {
      TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
      tflTensors[i].params.scale = quant->scale->data[0];
      tflTensors[i].params.zero_point = quant->zero_point->data[0];
    }
    if (tflTensors[i].allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tflTensors[i].data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t i = 0; i < 7; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 7; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteTensor* trained_model_input(int index) {
  return &ctx.tensors[inTensorIndices[index]];
}

static const int outTensorIndices[] = {
  14, 
};
TfLiteTensor* trained_model_output(int index) {
  return &ctx.tensors[outTensorIndices[index]];
}

TfLiteStatus trained_model_invoke() {
  for (size_t i = 0; i < 7; ++i) {
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
